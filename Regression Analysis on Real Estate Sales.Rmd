---
title: "Final Project"
author: "Gain Wang, Irene Hsueh, Eric Wang"
date: "June 11, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r,message=FALSE}
#read table (differs according to differnt file locations)
dat <- read.table("C:/Users/Gain/Desktop/realestate.txt", header = T)
#attach the data and scatter plot matrix


names(dat)
pairs(dat)
y=dat$SalePrice
x1=dat$SqFeet
x2=dat$Beds
x3=dat$Baths
x4=dat$Air
x5=dat$Garage
x6=dat$Pool
x7=dat$Year
x8=dat$Quality
x9=dat$Style
x10=dat$Lot
x11=dat$Highway
x4=factor(x4)
x6=factor(x6)
x8=factor(x8)
x9=factor(x9)
x11=factor(x11)
#stepwise regression with 
mod0=lm(y~1)
mod.upper = lm(y ~ x1 + x2 + x3 + x4+x5+x6+x7+x8+x9+x10+x11)
step(mod0, scope = list(lower = mod0, upper = mod.upper))
#summary of the stepwise model
mod.final=lm(y~x1+x8+x7+x10+x9+x3+x11+x5)
summary.mod=summary(mod.final)
summary(mod.final)
#best subset regression
library(leaps)
mod.sub=regsubsets(cbind(x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11),y)
summary(mod.sub)

#boxcox transformation
#boxcox transformation on each quantitative predictor
library(MASS)
boxcox.trans=boxcox(y~poly(x1,4))
boxcox.trans=boxcox(y~poly(x2,4))
boxcox.trans=boxcox(y~poly(x3,4))
boxcox.trans=boxcox(y~poly(x5,4))
boxcox.trans=boxcox(y~poly(x7,4))
boxcox.trans=boxcox(y~poly(x10,4))

x1new=1/sqrt(x1)
x10new=1/sqrt(x10)
x7new=1/sqrt(x7)
mod.upper = lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11)
mod.box = lm(y ~ x1new + x2 + x3 + x4 + x5 + x6 + x7new + x8 + x9 + x10new + x11)
#interaction term for quantitative variables
fit=lm(y~x1*x2*x3*x5*x7*x10)
summary(fit)


fit01=lm(y~x1)
plot(x1, y, xlab = 'SalePrice', ylab = 'SqFeet', main = 'SalePrice vs SqFeet', cex.lab = 1.3, cex.main = 1.5)
lines(x1, fitted(fit01), col = 2)
yhat01 = fitted(fit01)
e01 = y - yhat01
plot(yhat01, e01, xlab = 'Fitted Values', ylab = 'Residual', main = 'Residual vs Fit')
abline(h = 0, lty = 2)
qqnorm(e01)
qqline(e01)
summary(fit01)
ysqrt = y^.5
fit012 = lm(ysqrt ~ x1)
plot(x1, ysqrt, xlab = 'SalePrice', ylab = 'SqFeet', main = 'Sqrt SalePrice vs SqFeet', cex.lab = 1.3, cex.main = 1.5)
lines(x1, fitted(fit012), col = 2)
summary(fit012)

ylog = log(y)
fit013 = lm(ylog ~ x1)
plot(x1, ylog, xlab = 'SalePrice', ylab = 'SqFeet', main = 'Log SalePrice vs SqFeet', cex.lab = 1.3, cex.main = 1.5)
lines(x1, fitted(fit013), col = 2)
summary(fit013)

x1log = log(x1)
fit014 = lm(y ~ x1log)
plot(x1log, y, xlab = 'SalePrice', ylab = 'SqFeet', main = 'SalePrice vs Log SqFeet', cex.lab = 1.3, cex.main = 1.5)
lines(x1log, fitted(fit014), col = 2)
summary(fit014)


fit015 = lm(ylog ~ x1log)
plot(x1log, ylog, xlab = 'SalePrice', ylab = 'SqFeet', main = 'Log SalePrice vs Log SqFeet', cex.lab = 1.3, cex.main = 1.5)
lines(x1log, fitted(fit015), col = 2)
summary(fit015)

fit=lm(y~x1*x2*x3*x4*x5)
summary(fit)

mod.final=lm(y~x1+x8+x7+x9+x10+x11+x5)
yhat01=fitted(mod.final)
e01 = y - yhat01
plot(yhat01, e01, xlab = 'Fitted Values', ylab = 'Residual', main = 'Residual vs Fit')
abline(h = 0, lty = 2)
qqnorm(e01)
qqline(e01)

##categorical plot with mean response
plot(x1, y, type = 'n', xlab = 'Sqfeet', ylab = 'SalesPrice', main = 'Salesprice vs Sqfeet')
points(x1[x11 == 1], y[x11 == 1], col = 'blue')
points(x1[x11 == 0], y[x11 == 0], col = 'green')
legend('bottomright', bty = 'n', col = c('blue','green'), c('Highway', 'No Highway'), pch = c(1, 1))


plot(x1, y, type = 'n', xlab = 'Sqfeet', ylab = 'SalesPrice', main = 'Salesprice vs Sqfeet with quality')
points(x1[x8 == 1], y[x8 == 1], col = 1)
points(x1[x8 == 2], y[x8 == 2], col = 2)
points(x1[x8 == 3], y[x8 == 3], col = 3)
legend('bottomright', bty = 'n', col = c(1,2,3), c('1', '2', '3'), pch = c(1, 1,1))

plot(x1, y, type = 'n', xlab = 'Sqfeet', ylab = 'SalesPrice', main = 'Salesprice vs Sqfeet with style')
points(x1[x9 == 1], y[x9 == 1], col = 1)
points(x1[x9 == 2], y[x9 == 2], col = 2)
points(x1[x9 == 3], y[x9 == 3], col = 3)
points(x1[x9 == 4], y[x9 == 4], col = 4)
points(x1[x9 == 5], y[x9 == 5], col = 5)
points(x1[x9 == 6], y[x9 == 6], col = 6)
points(x1[x9 == 7], y[x9 == 7], col = 7)
points(x1[x9 == 8], y[x9 == 8], col = 8)
points(x1[x9 == 9], y[x9 == 9], col = 9)
points(x1[x9 == 10], y[x9 == 10], col = 10)
points(x1[x9 == 11], y[x9 == 11], col = 11)
legend('bottomright', bty = 'n', col = c(1,2,3,4,5,6,7,8,9,10,11), c('1', '2', '3', '4' ,'5', '6', '7','8','9','10','11'), pch = c(1, 1,1,1,1,1,1,1,1,1,1))

mod.final = lm(y ~ x1 + x8 + x7 + x10 + x9 + x11 + x2 + x1:x2 + x1:x7)
mod.full = lm(y ~ x1 + x8 + x7 + x10 + x9 + x11 + x5 + x2 + x1:x2 + x1:x7)
anova(mod.final, mod.full)

mod.final = lm(y ~ x1 + x8 + x7 + x10 + x9  + x2 + x1:x2 + x1:x7)
mod.full = lm(y ~ x1 + x8 + x7 + x10 + x9 + x11  + x2 + x1:x2 + x1:x7)
anova(mod.final, mod.full)

mod.final = lm(log(y) ~ x1 + x8 + x7 + x10 + x9 + x2 + x1:x2 + x1:x7)
yhat = fitted(mod.final)
e = log(y) - yhat
plot(yhat, e, xlab = 'Fitted Values', ylab = 'Residual', main = 'Residual vs Fit after log Transformation')
abline(h = 0, lty = 2)
qqnorm(e)
qqline(e)

# prediction interval
new150.000 = data.frame(x1 = 1.636, x8 = factor(3), x7 = 1950, x10 = 10.000, x9 = factor(1), x2 = 2)
predict(mod.final, newdata = new150.000, se.fit = TRUE, interval = 'prediction', level = 0.95)

new500.000 = data.frame(x1 = 3.644, x8 = factor(1), x7 = 1984, x10 = 21.895, x9 = factor(7), x2 = 3)
predict(mod.final, newdata = new500.000, se.fit = TRUE, interval = 'prediction', level = 0.95)

```
